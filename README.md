# ğŸ¦ TweetGPT â€” AI-Powered Tweet Generator

**TweetGPT** is a modern, full-stack application that uses **Groq** or **Ollama** LLM models to generate, evaluate, and refine tweets automatically â€” with no manual intervention. It integrates with **X (Twitter) OAuth** for secure login and posting, features a sleek, mobile-friendly UI built with **React + Vite**, and deploys via **Docker** with **Nginx** for production-ready frontend hosting.

ğŸ“¦ **GitHub Repo:** [https://github.com/ArchitJ6/TweetGPT](https://github.com/ArchitJ6/TweetGPT)

---

## âœ¨ Features

* ğŸ¤– **AI-Powered Tweet Generation** â€” Generates witty, snappy tweets using Groq or Ollama.
* ğŸ”„ **Iterative Optimization** â€” Auto-refines tweets until quality and engagement criteria are met.
* ğŸ” **X OAuth Integration** â€” Secure sign-in and direct posting to X.
* ğŸ¯ **Automatic Evaluation** â€” AI checks humor, originality, brevity, and style without manual review.
* âš¡ **Fast Model Switching** â€” Toggle between Groq and Ollama seamlessly.
* ğŸ¨ **Modern UI** â€” Responsive, Twitter-inspired interface.
* ğŸ“± **Mobile Friendly** â€” Optimized for all devices.
* ğŸ³ **Dockerized Deployment** â€” Backend, frontend, and Nginx all containerized.
* ğŸŒ **Nginx Hosting** â€” Production-grade static file serving.
* ğŸ“Š **Autonomous AI Workflow** â€” Fully automated generationâ€“evaluationâ€“refinement loop.

---

## ğŸ›  Tech Stack

| Layer               | Technology                           |
| ------------------- | ------------------------------------ |
| **Frontend**        | React, Vite, JavaScript, CSS         |
| **Backend**         | Python, Flask, LangChain, LangGraph  |
| **AI Models**       | Groq LLM, Ollama LLM                 |
| **Auth**            | X (Twitter) OAuth 2.0                |
| **Deployment**      | Docker, Docker Compose, Nginx        |
| **Version Control** | Git, GitHub                          |

---

## âš™ï¸ Prerequisites

* ğŸ Python **3.12**
* ğŸ¦ **X Developer Account** with API access
* ğŸ”‘ **Groq API Key**
* ğŸ’» **Ollama** installed (if using Ollama mode)
* ğŸ³ **Docker** & **Docker Compose**

---

## ğŸ§  AI Workflow

```mermaid
graph TD
    A[Start] --> B[Generate Tweet]
    B --> C[Evaluate Tweet]
    C -->|Approved| E[End]
    C -->|Needs Improvement| D[Refine Tweet]
    D --> C
```

**Steps:**

1. **Generate** â†’ AI crafts a humorous tweet based on the topic.
2. **Evaluate** â†’ AI reviews for creativity, humor, and shareability.
3. **Refine** â†’ AI improves the tweet if it doesnâ€™t pass.
4. **Loop** until approved or max iterations reached.

---

## ğŸ“‚ Project Structure

```
TweetGPT/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ llm_workflow.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ eslint.config.js
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ bot.svg
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â”œâ”€â”€ index.css
â”‚       â”œâ”€â”€ main.jsx
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ index.js
â”‚       â”‚   â”œâ”€â”€ NavigationBar.jsx
â”‚       â”‚   â””â”€â”€ NotificationBar.jsx
â”‚       â”œâ”€â”€ pages/
â”‚       â”‚   â”œâ”€â”€ GeneratorPage.jsx
â”‚       â”‚   â”œâ”€â”€ HomePage.jsx
â”‚       â”‚   â””â”€â”€ index.js
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ api.js
â”‚           â””â”€â”€ index.js
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ Setup & Run

### **1ï¸âƒ£ Clone Repository**

```bash
git clone https://github.com/ArchitJ6/TweetGPT.git
cd TweetGPT
```

### **2ï¸âƒ£ Configure Environment Variables**

ğŸ“ **Backend** (`backend/.env`)

```
cd backend
cp .env.example .env
```

```env
X_CLIENT_ID=""
X_CLIENT_SECRET=""
X_REDIRECT_URI="http://localhost:5000/callback"
X_AUTH_URL="https://twitter.com/i/oauth2/authorize"
X_TOKEN_URL="https://api.twitter.com/2/oauth2/token"
GROQ_API_KEY="your_groq_api_key"
USE_OLLAMA="true_or_false"
GROQ_LLM_MODEL_NAME="your_groq_llm_model_name"
OLLAMA_MODEL_NAME="your_ollama_model_name"
```

ğŸ“ **Frontend** (`frontend/.env`)

```
cd frontend
cp .env.example .env
```

```env
VITE_API_BASE_URL="http://localhost:5000"
```

### **3ï¸âƒ£ Run Without Docker (Optional)**

ğŸ”¹ **Backend**

```bash
cd backend
pip install -r requirements.txt
python app.py
```

ğŸ”¹ **Frontend**

```bash
cd frontend
npm install
npm run dev
```

### **4ï¸âƒ£ Run With Docker (Recommended)**

```bash
docker-compose up --build
```

Frontend will be served via **ğŸŒ Nginx** at `http://localhost:5173` and backend will run at `http://localhost:5000`.

---

## ğŸ“¸ Screenshots

![Home](assets/images/1.png)
![Tweet Generated](assets/images/2.png)
![Tweet Optimization History](assets/images/3.png)

---

## ğŸ“œ License

MIT License â€” free to use and modify.

---

## ğŸ¤ Contributing

PRs welcome! Please follow the existing code style.

---

**Made with â¤ï¸ by Archit Jain**
